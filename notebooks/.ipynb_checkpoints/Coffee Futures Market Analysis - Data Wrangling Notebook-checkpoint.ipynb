{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coffee Market Analysis\n",
    "## Data-Wrangling Notebook\n",
    "\n",
    "### Matthew Garton - February 2019\n",
    "\n",
    "**Purpose:** The purpose of this notebook is to acquire my data, inspect it, clean it and prepare it for EDA and modeling.\n",
    "\n",
    "**Context**: The ultimate goal of my project is to develop trading signals for coffee futures. I will attempt to build a machine learning model which uses fundamental and technical data to predict the future direction of coffee futures price changes. My expectation at the outset of this project is that my feature matrix will include data on weather, GDP, and coffee production and exports in major coffee-producing nations, GDP and coffee import data in major coffee-importing nations, as well as volume, open-interest, and commitment of traders data for ICE coffee futures contracts.\n",
    "\n",
    "Note that many of the decisions made and functions written here came up at various stages of the project, from initial inspection all the way to model-building (as is the non-linear nature of the data science workflow). To keep things clean, I have moved all of the data cleaning/prep (outside of train-test splitting and some feature engineering) to this notebook. The csv file that I output can then be accessed in other notebooks in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering data\n",
    "\n",
    "1. Price data (1973-2019) - daily OHLC prices (plus Volume and OI) for ICE Coffee 'C' futures.\n",
    "\n",
    "    source: [Wiki Continuous Futures database on Quandl](https://www.quandl.com/data/CHRIS-Wiki-Continuous-Futures)\n",
    "      \n",
    "      \n",
    "2. Weather data (1991-2015) - monthly average temperature (celsius) and rainfall (mm) for the top five coffee exporting countries (Brazil, Vietnam, Colombia, Indonesia, Ethiopia).\n",
    "    \n",
    "    source: [World Bank Climate Change Knowledge Portal](http://sdwebx.worldbank.org/climateportal/index.cfm?page=downscaled_data_download&menu=historical)\n",
    "    \n",
    "    \n",
    "3. Fundamental data (1990-2017) - annual data on coffee production, imports, exports, etc. from International Coffee Organization*.\n",
    "\n",
    "    source: [International Coffee Organization](http://www.ico.org/new_historical.asp?section=Statistics)\n",
    "\n",
    "\n",
    "4. Positioning data (1995-2016) - monthly Commitment of Traders' reports from CFTC\n",
    "\n",
    "    source: [Commodity Futures Trading Commission](https://www.cftc.gov/MarketReports/CommitmentsofTraders/HistoricalCompressed/index.htm)\n",
    "    \n",
    "*Note: Before getting started here, I did some initial data assembling/cleaning in excel, so if you choose to get the data directly from the sources listed above, some preparation will be necessary before getting it into the format shown here. The biggest decision I made so far was in how to handle some of the ICO data which was indexed by 'Crop Year' rather than 'Calendar Year'. My initial solution is to treat the most recent year of the 'Crop Year' as the relevant 'year' for the data (so Crop Year 1991/1992 is treated as Year 1992, with the understanding that all of the data for the 1991-1992 period would have been availably by EOY 1992). For now, this is a simplifying assumption to avoid any 'look-ahead bias.' This might be an oversimplification that I'll have to come back to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Daily ICE Coffee 'C' Futures price data\n",
    "coffee = pd.read_csv('../data/CHRIS-ICE_KC1.csv')\n",
    "\n",
    "# import Monthly Weather data for major coffee producing countries\n",
    "weather = pd.read_csv('../data/Weather.csv')\n",
    "\n",
    "# import Annual fundamental (Production, Exports, Imports, etc.) data\n",
    "fundamental = pd.read_csv('../data/SupplyDemand.csv')\n",
    "\n",
    "# import Monthly Commitment of Traders report data\n",
    "cot = pd.read_csv('../data/CommitmentOfTraders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Temperature (Monthly – C)</th>\n",
       "      <th>Precip (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/31/91</td>\n",
       "      <td>BRA</td>\n",
       "      <td>25.6430</td>\n",
       "      <td>260.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/28/91</td>\n",
       "      <td>BRA</td>\n",
       "      <td>25.9575</td>\n",
       "      <td>193.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/31/91</td>\n",
       "      <td>BRA</td>\n",
       "      <td>25.6557</td>\n",
       "      <td>238.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/30/91</td>\n",
       "      <td>BRA</td>\n",
       "      <td>25.3129</td>\n",
       "      <td>194.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/31/91</td>\n",
       "      <td>BRA</td>\n",
       "      <td>24.7910</td>\n",
       "      <td>119.090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date Country  Temperature (Monthly – C)  Precip (mm)\n",
       "0  01/31/91     BRA                    25.6430      260.878\n",
       "1  02/28/91     BRA                    25.9575      193.859\n",
       "2  03/31/91     BRA                    25.6557      238.866\n",
       "3  04/30/91     BRA                    25.3129      194.848\n",
       "4  05/31/91     BRA                    24.7910      119.090"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick fix to 'Country' column typo..\n",
    "weather.rename(index=str, columns={' Country':'Country'}, inplace=True)\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataframe, index by Date (as datetime object) and extract year, month\n",
    "dfs = [coffee, weather, fundamental, cot]\n",
    "for df in dfs:\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "# coffee and cot are sorted backwards; reverse order\n",
    "coffee.sort_index(inplace=True)\n",
    "cot.sort_index(inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For weather data, what I want is one row per observation, with each country's\n",
    "# data represented in columns of that row\n",
    "\n",
    "countries = ['BRA', 'COL', 'ETH', 'IDN', 'VNM']\n",
    "\n",
    "# split weather into dfs for each country and rename columns appropriately\n",
    "dfs = []\n",
    "for country in countries:\n",
    "    df = weather[weather['Country'] == country]\n",
    "    df.rename(index=str, \n",
    "              columns={'Temperature (Monthly – C)':'{}_Temp'.format(country),\n",
    "                       'Precip (mm)':'{}_Precip'.format(country)}, inplace=True)\n",
    "    df.drop(columns=['Country'], inplace=True)\n",
    "    dfs.append(df)\n",
    "\n",
    "# combine separate countries' weather data into one frame indexed by date\n",
    "weather = dfs[0]\n",
    "\n",
    "for df in dfs[1:]:\n",
    "    cols = df.columns.difference(weather.columns)\n",
    "    weather = weather.merge(df[cols], left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all data into one dataframe (using only the 1995-2015 window where they overlap)\n",
    "dfs = [coffee['1995':'2016'], weather['1995':'2016'], fundamental['1995':'2016'], cot['1995':'2016']]\n",
    "\n",
    "coffee_data = pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5484, 58)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
